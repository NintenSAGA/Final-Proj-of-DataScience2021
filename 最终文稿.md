## 数据科学基础大作业-司法大数据自动化标注与分析

谭子悦 李佳骏 邱兴驰

### 1. 选题理解、思路

司法大数据，是个人民法庭在司法工作中形成的审判流程、执行信息、法律文书、庭审活动信息、司法政务、司法人事、外部协查等数据的总和及其关联关系。这些数据既包括审判执行活动中每天录入或产生的案件基本情况等结构化信息，也包括诸如起诉书、裁判文书等半结构化数据，还包括庭审活动录音录像、图像视频类证据等非结构化数据。而通过挖掘案件、人员、财物、外部信息等数据之间的关联关系，我们可以探索发现蕴藏其中的司法活动和社会发展规律。

司法大数据在中国法院最基础的应用在于通过大数据挖掘分析，利用类案推荐、文书自动纠错、文书自动生成、判决结果预测等功能建立智能辅助办案系统，而这其中所需要的数据主要来源于裁判文书。因此，本项目主要聚焦于司法大数据中的裁判文书，一种非结构化数据。

本项目的目标在于构建自动化裁判文书爬取与标注分析系统，其主要功能模块包括：

1. 爬虫模块：利用自动化web工具从文献源获取指定数量的裁判文书，并提取净化文本。案件以刑事为主。
2. 自动化标注模块：以爬虫模块获得的数据（或手动导入数据）作为数据源，分析并标注每一篇裁判文书中的属性标签（含通用属性和特别属性）
3. 分析统计模块：对标注结果进行数据可视化处理，呈现可能的统计结果

本系统通过Python编写，最终产品为本地GUI程序 (支持macOS与Windows)

#### 1.1 爬虫

爬虫部分的总体思路为：

> 1. 给定参数：搜索目标，限制条件，目标条数……
> 2. 利用自动化Web工具获取目标网页上的全部相关条目对应的URL，将URL条目存在URL_LIST中
> 3. 根据URL_LIST取回HTML文件缓存在本地文件夹
> 4. 利用HTML解析工具提取文本
> 5. 对文本进行净化与切分，输出纯文本

功能特性：

- 可以指定需要爬取的文书数量、年份、日期等参数
- 可以在客户端进行自动化爬取
- 可以分别设置：
  - 只爬取URL_LIST
  - （已有URL_LIST时）直接取回HTML并提取文本
  - （已有HTML缓存时）直接提取文本

#### 1.2 自动化标注

自动化标注部分的总体思路为：

> 1. 输入从爬虫模块获取的文本
> 2. 根据先行制定的用户词典，对文本进行分词处理与词性分类
> 3. 将结果分类放入各属性Tag的候选列表中，列表里按可能性从高到低排序
> 4. 输出以属性名称与对应候选列表为键值对的字典

功能特性：

- 可以识别出以下属性：姓名、省份、城市、审理法院、罪名、主刑、附加刑、酒精含量、时间
  - 省份与城市为审理所在地
  - 酒精含量仅在危险驾驶罪中可获取
  - 主刑包含：管制、拘役、有期徒刑、无期徒刑、死刑
  - 附加刑包含：没收、罚金

#### 1.3 菜单界面

菜单界面含“爬取文书”与“自动化标注”两个界面

“爬取文书”界面有以下功能

> 1. 可以选取文书源（最终经可靠性测试后仅保留了“北大法宝”源）
> 2. 可以设置爬取选项：爬取url_list及爬取html_list
> 3. 可以设置爬取年份及文书数量
>    - 会自动根据输入参数检查本地缓存，判断是否可不勾选上述爬取选项
> 4. 可以显示爬虫程序的控制台输出信息

#### 1.4 拓展

在获取到标注数据后，我们将围绕以下几个主题进行数据分析：

1. 探究各省份对危险驾驶罪的主刑与附加刑判决与当事人的酒精摄入量是否存在近似函数关系
2. 假如1成立，则利用这一函数关系探究各省份危险驾驶罪案发率与其处罚标准是否存在关联
3. 统计各罪由主刑与附加刑结果的方差，据此探究各罪由审判结果的差异程度


### 2. 实现

#### 2.1 爬虫

<img src="./resources/Crawling-map.png" alt="Crawling-map"/>

如图所示，爬虫部分可拆分为两个大模块：url_fetch和text_extract

实现流程为：

> **A. url_fetch**
>
> 1. 利用Selenium作为自动化爬取工具
> 2. Web Driver选用Microsoft Edge
>    - 可自动识别系统切换不同的Web Driver内核（仅支持macOS和Windows)
>    - 使用前需先安装Microsoft Edge
> 3. 打开网页
>    - 文书来源可选裁判文书网、北大法宝、中华人民共和国最高法院公报
>    - 出于运行稳定性考虑，优先选择北大法宝作为来源（需在南大内网使用）
> 4. 根据给定参数设置筛选条件
>    - 默认选择 普通案例、刑事一审、判决书
> 5. 获取`n`个条目链接，存储于 `./result/~url_list.txt`
>
> **B. text_extract**
>
> 1. 建立`mechanicalsoup.StatefulBrowser`对象browser
>
> 2. 将Selenium Web Driver的cookies转移给browser，防止因并发访问被网站屏蔽
>
> **a. html_file_retrieve**
>
> 3. 用browser获取`url_list.txt`中每一个条目对应的HTML文档
>
> **b. html_text_retrieve**
>
> 4. 利用Beautiful Soup提取每一个HTML文档中的文本
> 5. 提炼文本，得到最终的纯文本，储存为 `[序号].[文书名].txt`



#### 2.2 自动化标注

<img src="resources/NLP-map.png"   alt="NLP-map"/> 

如图所示，自动化标注（NLP）部分主要由一个公共API，两个处理步骤组成

以下是一些实现细节：

> **A. cal_word_freq**
>
> 对从公共API获得的文本进行预处理
>
> 1. 该部分使用先行定义的用户辞典，采用Jieba进行分词处理与词性分类
>    - 用户辞典包括：全国法院信息、罪名表、全国省级与市级行政区名单、其他自定义信息
> 2. 除此之外，利用正则表达式单独对酒精含量、主刑、附加刑进行识别与获取
>    - 此三类属性只提供单一候选项，若无匹配结果则返回空字符串，留给下游处理
>
> **B. parse_word_freq**
>
> 对上一部分获得的词频字典进行分类处理，输入参数中含原文本，供补漏操作
>
> 1. 将酒精、主刑、附加刑三类归档，只取唯一可能
> 2. 将法院信息归档，从法院信息中提取地区信息，填入省份、城市的候选列表
> 3. 将姓名、省份、城市、罪名等多可能项归档
> 4. 处理边缘情况
>    1. 若为省份直辖市，则城市名同省份
>    2. 若未找到省份信息，但已有城市信息，则用预处理的逆向匹配表获取省份信息
>    3. 若未获得审理法院信息但有城市与省份信息，则将法院归于该市的中级人民法院
>    4. 利用正则表达式从原文本中单独获取罪名信息，装入罪名候选列表，再重新计算词频并排序
>       - 此步骤目的在于防止遗失罪名，或错误匹配罪名

#### 2.3 菜单界面 

目前界面主要可分为三个部分：选择界面、爬虫界面、批注界面

后续还将增加数据可视化界面

##### a. 选择页面

<img src="./resources/panel0.png" alt="Crawling-map" width="30%" />

选择页面包含其他功能模块的入口

##### b. 爬虫界面

<img src="./resources/panel1.png" alt="Crawling-map" width="30%" />

爬虫界面可选择文献来源，设置爬取选项与爬取参数

下设文本框及时显示运行日志

##### c. 标注界面

<img src="./resources/panel2.png" alt="Crawling-map" width="50%" />

标注界面可分为两个功能页面，左侧为文书原文显示，右侧为对应属性标签选项，自动化标注引擎会先行勾选最为可能的属性标签。

### 3. 当前进度展示

#### 3.1 爬虫

【放个视频，自己看吧您】

当前已实现内容：

1. 已完全实现自动化爬取功能（即一键爬取）
2. 可指定爬取数目与开始页（当前测试最高可稳定爬取1000份）
3. 可自动剔除噪音信息（如北大法宝嵌入在HTML中的反爬虫文字）
4. 可自动分段出审判结果与参考条文

有待实现的功能：

1. 限定年月日检索
2. 更多自定义参数（一审、二审等）

#### 3.2 自动化标注

当前已实现内容：

1. 已实现基本文书信息提取（姓名，性别，地区，罪名，法院等）

2. 可以在数据集中筛选**最优的标注信息**（将最有可能被标注的信息优先排列）

3. 已经可以将标注信息保存为 **标注.json**

有待实现的内容：

1. 提高分词准确度

2. 提高最优标注信息的准确性

3. 对多当事人案件的分析

4. hanlpVersion 自动化标注

#### 3.3 拓展

当前已实现内容：

1. 对危险驾驶的部分信息进行了提取

2. 其他可以用来进行相似文书推荐的信息，已经在**3.2 自动化标注**中提取

待实现：

1. 利用筛选数据集，自动推荐相似文书
